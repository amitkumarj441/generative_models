{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models, losses, optimizers\nimport os\nfrom tqdm import tqdm\nimport time\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-22T23:59:47.172600Z","iopub.execute_input":"2023-02-22T23:59:47.173549Z","iopub.status.idle":"2023-02-22T23:59:54.780876Z","shell.execute_reply.started":"2023-02-22T23:59:47.173455Z","shell.execute_reply":"2023-02-22T23:59:54.779869Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(generator, gen_input, path, show=False):\n    dirname = os.path.dirname(path)\n    if not os.path.isdir(dirname):\n        os.mkdir(dirname)\n\n    predictions = generator(gen_input, training=False)\n\n    fig = plt.figure(figsize=(4, 4))\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(predictions[i])\n        plt.axis('off')\n\n    plt.savefig(path)\n    plt.close(fig)\n\n    if show:\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:00:00.569517Z","iopub.execute_input":"2023-02-23T00:00:00.570139Z","iopub.status.idle":"2023-02-23T00:00:00.577405Z","shell.execute_reply.started":"2023-02-23T00:00:00.570104Z","shell.execute_reply":"2023-02-23T00:00:00.576324Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# HYPERPARAMETERS\nBATCH_SIZE = 256\nEPOCHS = 300\nmse = losses.MeanSquaredError()\nmodel_optimizer = optimizers.legacy.Adam(1E-4)\nTIMESTEPS = 100\n\nlinear_beta_schedule = tf.linspace(0.0001, 0.005, TIMESTEPS)\n\nbetas = linear_beta_schedule\nalphas = 1. - betas\nalphas_cumprod = tf.math.cumprod(alphas, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:00:41.873104Z","iopub.execute_input":"2023-02-23T00:00:41.873485Z","iopub.status.idle":"2023-02-23T00:00:44.384038Z","shell.execute_reply.started":"2023-02-23T00:00:41.873451Z","shell.execute_reply":"2023-02-23T00:00:44.383049Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!mkdir generated\n!mkdir training_checkpoints","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:05:07.716194Z","iopub.execute_input":"2023-02-23T00:05:07.716905Z","iopub.status.idle":"2023-02-23T00:05:09.660725Z","shell.execute_reply.started":"2023-02-23T00:05:07.716868Z","shell.execute_reply":"2023-02-23T00:05:09.659567Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n","output_type":"stream"}]},{"cell_type":"code","source":"GEN_DIR = 'generated'\nCHECKPOINT_DIR ='training_checkpoints'\nCHECKPOINT_PREFIX = os.path.join(CHECKPOINT_DIR, \"ckpt\")\nCHECKPOINT_SAVE_FREQUENCY = EPOCHS // 10","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:01:31.972062Z","iopub.execute_input":"2023-02-23T00:01:31.972447Z","iopub.status.idle":"2023-02-23T00:01:31.978014Z","shell.execute_reply.started":"2023-02-23T00:01:31.972413Z","shell.execute_reply":"2023-02-23T00:01:31.977012Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# DATASET\nINPUT_SHAPE = (32, 32, 3)\n(train_images, _), (test_images, _) = datasets.cifar10.load_data()\ntrain_images = train_images.reshape((-1, *INPUT_SHAPE)).astype('float32')\ntest_images = test_images.reshape((-1, *INPUT_SHAPE)).astype('float32')\ntrain_images = train_images / 255\ntest_images = test_images / 255\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_images)).shuffle(len(train_images)).batch(256)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:01:43.102560Z","iopub.execute_input":"2023-02-23T00:01:43.102975Z","iopub.status.idle":"2023-02-23T00:01:51.433594Z","shell.execute_reply.started":"2023-02-23T00:01:43.102937Z","shell.execute_reply":"2023-02-23T00:01:51.432550Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 4s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def forward_diffusion(x0, t):\n    \"\"\"\n        q(xt|xt-1) ~ N(√a*xt-1; (1-a)*I)\n        q(xt|x0) ~ N(√ā*x0; (1-ā)*I)\n        q(xt|x0) = √ā*x0 + √(1-ā)*ε\n    \"\"\"\n    x0_shape = tf.shape(x0)\n    noise = tf.random.normal(shape=x0_shape)\n    alphas_cumprod_t = tf.reshape(tf.gather(alphas_cumprod, t), (-1, *((1,)*(len(x0_shape)-1))))\n    return tf.sqrt(alphas_cumprod_t) * x0 + tf.sqrt(1 - alphas_cumprod_t) * noise, noise","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:02:02.075838Z","iopub.execute_input":"2023-02-23T00:02:02.076203Z","iopub.status.idle":"2023-02-23T00:02:02.083529Z","shell.execute_reply.started":"2023-02-23T00:02:02.076163Z","shell.execute_reply":"2023-02-23T00:02:02.081939Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def backward_model():\n    \"\"\"\n        pθ(xt-1|xt) ~ N(µθ(xt,t); σθ²(xt,t))\n    \"\"\"\n    x1 = layers.Input(shape=INPUT_SHAPE, dtype='float32')\n    x2 = layers.Input(shape=(TIMESTEPS,), dtype='float32')\n\n    x2_ = layers.Dense(INPUT_SHAPE[0]*INPUT_SHAPE[1]*INPUT_SHAPE[2], use_bias=False)(x2)\n    x2_ = layers.Reshape(INPUT_SHAPE)(x2_)\n    x = layers.concatenate([x1, x2_])\n\n    # (32, 32, 64)\n    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n    x = layers.LeakyReLU()(x)\n\n    # (16, 16, 128)\n    x = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.LeakyReLU()(x)\n\n    # (8, 8, 128)\n    x = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.LeakyReLU()(x)\n\n    # (4, 4, 256)\n    x = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.LeakyReLU()(x)\n\n    x = layers.Dropout(0.3)(x)\n\n    # (8, 8, 128)\n    x = layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n\n    # (16, 16, 128)\n    x = layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU()(x)\n\n    # (32, 32, 3)\n    y = layers.Conv2DTranspose(3, (3, 3), padding='same', use_bias=False, activation='sigmoid')(x)\n\n    return models.Model(inputs=[x1, x2], outputs=[y])","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:02:17.360379Z","iopub.execute_input":"2023-02-23T00:02:17.360736Z","iopub.status.idle":"2023-02-23T00:02:17.373412Z","shell.execute_reply.started":"2023-02-23T00:02:17.360705Z","shell.execute_reply":"2023-02-23T00:02:17.372336Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def train(diffusion_model, dataset, epochs, seed=None, checkpoint=None):\n    for epoch in tqdm(range(epochs)):\n        start = time.time()\n\n        for step, image_batch in enumerate(dataset):\n            mse_loss = train_step(diffusion_model, image_batch)\n            print(f'  Step: {step} - Train loss: {mse_loss}')\n\n        if seed is not None:\n            generate_and_save_images(diffusion_model, seed, f'{GEN_DIR}/{epoch+1:03d}.png')\n\n        if checkpoint is not None and (epoch+1) % CHECKPOINT_SAVE_FREQUENCY == 0:\n            checkpoint.save(file_prefix=CHECKPOINT_PREFIX)\n\n        print(f'Epoch {epoch+1:03d}: {time.time()-start:.0f} seconds')\n\n    checkpoint.save(file_prefix=CHECKPOINT_PREFIX)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:02:30.049118Z","iopub.execute_input":"2023-02-23T00:02:30.049493Z","iopub.status.idle":"2023-02-23T00:02:30.057275Z","shell.execute_reply.started":"2023-02-23T00:02:30.049460Z","shell.execute_reply":"2023-02-23T00:02:30.056168Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(diffusion_model, images):\n    random_ts = tf.random.uniform((len(images),), 0, TIMESTEPS, dtype=tf.int32)\n    noisy_images, noises = forward_diffusion(images, random_ts)\n\n    with tf.GradientTape() as tape:\n        noises_pred = diffusion_model(noisy_images, tf.one_hot(random_ts, TIMESTEPS))\n        train_loss = mse(noises, noises_pred)\n\n    grads = tape.gradient(train_loss, diffusion_model.trainable_variables)\n    model_optimizer.apply_gradients(zip(grads, diffusion_model.trainable_variables))\n\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:02:57.528054Z","iopub.execute_input":"2023-02-23T00:02:57.528500Z","iopub.status.idle":"2023-02-23T00:02:57.537373Z","shell.execute_reply.started":"2023-02-23T00:02:57.528464Z","shell.execute_reply":"2023-02-23T00:02:57.535538Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def plot_img_forward_diffusion(x0, num_images=10, path=None):\n    fig, axes = plt.subplots(1, num_images, figsize=(9, 2))\n\n    for i, t in enumerate(range(0, TIMESTEPS, TIMESTEPS // num_images)):\n        noisy_image, _ = forward_diffusion(x0, t)\n        axes[i].set_title(f't = {t}')\n        axes[i].imshow(noisy_image)\n\n    if path is not None:\n        plt.savefig(path)\n\n    plt.close(fig)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:03:10.855194Z","iopub.execute_input":"2023-02-23T00:03:10.855922Z","iopub.status.idle":"2023-02-23T00:03:10.863004Z","shell.execute_reply.started":"2023-02-23T00:03:10.855885Z","shell.execute_reply":"2023-02-23T00:03:10.861877Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def plot_img_backward_diffusion(diffusion_model, seed=None, num_images=10, path=None):\n    fig, axes = plt.subplots(1, num_images, figsize=(9, 2))\n\n    xT = seed if seed is not None else tf.random.normal(shape=(1, *INPUT_SHAPE))\n    for i, t in enumerate(reversed(range(0, TIMESTEPS, TIMESTEPS // num_images))):\n        axes[i].set_title(f't = {t}')\n        axes[i].imshow(xT[0])\n        noise_pred = diffusion_model(xT, tf.one_hot(t, TIMESTEPS))\n        xT = 1/tf.sqrt(alphas[t]) * (xT - betas[t]/tf.sqrt(1-alphas_cumprod[t])*noise_pred)\n        if t > 0:\n            xT += tf.sqrt(betas[t]) * tf.random.normal(shape=tf.shape(xT))\n\n    if path is not None:\n        plt.savefig(path)\n\n    plt.close(fig)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:03:26.909262Z","iopub.execute_input":"2023-02-23T00:03:26.909665Z","iopub.status.idle":"2023-02-23T00:03:26.917637Z","shell.execute_reply.started":"2023-02-23T00:03:26.909630Z","shell.execute_reply":"2023-02-23T00:03:26.916651Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    diffusion_model = backward_model()\n    seed = tf.random.normal(shape=(1, *INPUT_SHAPE))\n    plot_img_forward_diffusion(train_images[0])","metadata":{"execution":{"iopub.status.busy":"2023-02-23T00:05:25.612186Z","iopub.execute_input":"2023-02-23T00:05:25.613185Z","iopub.status.idle":"2023-02-23T00:05:25.926684Z","shell.execute_reply.started":"2023-02-23T00:05:25.613144Z","shell.execute_reply":"2023-02-23T00:05:25.925720Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}